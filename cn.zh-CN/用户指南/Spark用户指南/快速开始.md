# 快速开始 {#concept_f1r_5tc_kgb .concept}

本章节将指导使用者使用MaxCompute Spark快速构建Spark on MaxCompute的应用，并在MaxCompute项目中提交执行Spark作业。

## 快速开始 {#section_zsg_2rb_kgb .section}

-   下载MaxCompute Spark发布包

    -   [spark-1.6.3](http://repo.aliyun.com/download/spark-1.6.3-public.tar.gz)
    -   [spark-2.3.0](http://repo.aliyun.com/download/spark-2.3.0-public.tar.gz)
    通过MaxCompute Spark发布包可以在本地通过spark-submit方式提交作业。如果您需要使用Spark-1.x版本，请选择spark-1.6.3发布包。需要Spark-2.x请下载spark-2.3.0发布包。

    MaxCompute集群同时支持spark1.x、spark2.x，服务侧将根据用户提交任务的MaxCompute Spark版本自动启动对应版本服务。

    发布包的目录结构和社区的Spark完全一致，其中conf目录下有spark-defaults.conf作为默认配置参数的文件。bin目录下目前只支持使用spark-submit来提交作业，spark-shell、spark-sql目前都还不支持。

    ```
    1.
    2.|-- RELEASE
    3.|-- bin
    4.|-- conf
    5.|-- lib
    6.|-- python
    7.`-- sbin
    
    ```

-   环境准备

    JAVA\_HOME设置

    ```
    # 尽量使用 JDK 1.7+
    # 1.8+ 最佳
    export JAVA_HOME=/path/to/jdk
    export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
    export PATH=$JAVA_HOME/bin:$PATH
    ```

    SPARK\_HOME设置

    ```
    export SPARK_HOME=/path/to/spark_extracted_package
    export PATH=$SPARK_HOME/bin:$PATH
    ```

    本地开发环境有Maven3.3.3以上。

-   设置Spark-defaults.conf

    在**$SPARK\_HOME/conf**路径下存在spark-defaults.conf.template文件，这个可以作为spark-defaults.conf的模版，需要在该文件中设置MaxCompute相关的账号信息后，才可以提交Spark任务到MaxCompute。默认配置内容如下，将空白部分根据实际的账号信息填上即可，其余的配置可以保持不变。

    ```
    # OdpsAccount Info Setting
    spark.hadoop.odps.project.name =
    spark.hadoop.odps.access.id =
    spark.hadoop.odps.access.key =
    spark.hadoop.odps.end.point = http://service.cn.maxcompute.aliyun.com/api
    ```

    各配置项含义说明：

    |配置项|说明|
    |---|--|
    |     ```
spark.hadoop.odps.project.name
    ```

 |填写MaxCompute项目名称|
    |`spark.hadoop.odps.access.id`|填写MaxCompute用户的accessKeyId|
    |`spark.hadoop.odps.access.key`|填写MaxCompute用户的accessKeySecret|
    |`spark.hadoop.odps.end.point`|填写项目所在region的MaxCompute Endpoint，如：http://service.cn.maxcompute.aliyun.com/api|

-   主要模块以及Maven依赖说

    项目中Spark相关的依赖模块主要有三个：

    -   cupid-sdk**\[开源应用接入MaxCompute SDK\]**
    -   odps-spark-datasource\_2.10**\[Spark-1.x MaxCompute数据访问API\]**
    -   odps-spark-datasource\_2.11**\[Spark-2.x MaxCompute数据访问API\]**
    ```
    # scope请设置为provided
    # 另外如依赖spark-core spark-sql等模块，也请统一设置为provided
    <dependency>
    	<groupId>com.aliyun.odps</groupId>
    	<artifactId>cupid-sdk</artifactId>
    	<version>3.3.2-public</version>
    	<scope>provided</scope>
    </dependency>
    
    # Spark-1.x请依赖此模块
    <dependency>
    	<groupId>com.aliyun.odps</groupId>
    	<artifactId>odps-spark-datasource_2.10</artifactId>
    	<version>3.3.2-public</version>
    </dependency>
    
    # Spark-2.x请依赖此模块
    <dependency>
      	<groupId>com.aliyun.odps</groupId>
      	<artifactId>odps-spark-datasource_2.11</artifactId>
      	<version>3.3.2-public</version>
    </dependency>
    ```

-   应用开发并提交运行

    MaxCompute Spark提供两个应用构建模版，用户可以基于此模版进行开发，最后统一构建整个项目后用生成的应用包即可直接提交到MaxCompute集群上运行Spark应用。

    -   [Spark-Examples for Spark-1.x](https://github.com/aliyun/aliyun-cupid-sdk/blob/3.3.2-public/spark/spark-1.x/spark-examples)
    -   [Spark-Examples for Spark-2.x](https://github.com/aliyun/aliyun-cupid-sdk/blob/3.3.2-public/spark/spark-2.x/spark-examples)
    应用模板脚本需要使用[maven](https://maven.apache.org/download.cgi)，请检查运行环境中是否安装和正确配置。

    以下例子分别使用spark1.x和spark2.x的模板脚本创建应用，通过spark-submit以yarn-cluster模式在MaxCompute项目中运行SparkPi，请确保

    ```
    Spark-defaults.conf
    ```

    中正确配置了MaxCompute项目及认证信息。

-   MaxCompute Spark-1.x Demo

    可通过[Create-AliSpark-1.x-APP.sh](https://github.com/aliyun/aliyun-cupid-sdk/blob/3.3.2-public/archetypes/Create-AliSpark-1.x-APP.sh) 脚本快速场景一个用于QuickStart的Maven Project。

    ```
    # Usage: sh Create-AliSpark-1.x-APP.sh <app_name> <target_path>
    sh Create-AliSpark-1.x-APP.sh spark-1.x-demo /tmp/
    cd /tmp/spark-1.x-demo
    mvn clean package
    
    # 冒烟测试 
    # 1 利用编译出来的 shaded jar包
    # 2 按照文档所示下载MaxCompute Spark客户端
    # 3 参考文档”置环境变量”指引，填写MaxCompute项目相关配置项
    
    # 执行spark-submit命令 如下
    $SPARK_HOME/bin/spark-submit \
            --master yarn-cluster \
            --class SparkPi \
            /tmp/spark-1.x-demo/target/AliSpark-1.x-quickstart-1.0-SNAPSHOT-shaded.jar
    ```

-   MaxCompute Spark-2.x Demo

    可通过 [Create-AliSpark-2.x-APP.sh](https://github.com/aliyun/aliyun-cupid-sdk/blob/3.3.2-public/archetypes/Create-AliSpark-2.x-APP.sh) 脚本快速场景一个用于QuickStart的Maven Project。

    ```
    # Usage: sh Create-AliSpark-2.x-APP.sh <app_name> <target_path>
    sh Create-AliSpark-2.x-APP.sh spark-2.x-demo /tmp/
    cd /tmp/spark-2.x-demo
    mvn clean package
    
    # 冒烟测试 
    # 1 利用编译出来的 shaded jar包
    # 2 按照文档所示下载MaxCompute Spark客户端
    # 3 参考文档”置环境变量”指引，填写MaxCompute项目相关配置项
    
    # 执行spark-submit命令 如下
    $SPARK_HOME/bin/spark-submit \
            --master yarn-cluster \
            --class SparkPi \
          /tmp/spark-2.x-demo/target/AliSpark-2.x-quickstart-1.0-SNAPSHOT-shaded.jar
    ```

-   作业查看

    提交作业后根据日志检查作业是否正常提交并执行：

    ```
    cd $SPARK_HOME
    bin/spark-submit --master yarn-cluster --class  SparkPi /tmp/spark-2.x-demo/target/AliSpark-2.x-quickstart-1.0-SNAPSHOT-shaded.jar
    作业提交成功后，MaxCompute会创建一个instance，在日志中会打印instance的logview:
    19/01/05 20:36:47 INFO YarnClientImplUtil: logview url: http://logview.odps.aliyun.com/logview/?h=http://service.cn.maxcompute.aliyun.com/api&p=qn_beijing&i=20190105123647703gpqn26pr2&token=eG94TG1iTkZDSFErc1ZPcUZyTTdSWWQ3UE44PSxPRFBTX09CTzoxODc1NjUzNjIyNTQzMDYxLDE1NDY5NTEwMDcseyJTdGF0ZW1lbnQiOlt7IkFjdGlvbiI6WyJvZHBzOlJlYWQiXSwiRWZmZWN0IjoiQWxsb3ciLCJSZXNvdXJjZSI6WyJhY3M6b2RwczoqOnByb2plY3RzL3FuX2JlaWppbmcvaW5zdGFuY2VzLzIwMTkwMTA1MTIzNjQ3NzAzZ3BxbjI2cHIyIl19XSwiVmVyc2lvbiI6IjEifQ==
    成功标准: <看到以下输出，可能会有其他日志一并输出>
    19/01/05 20:37:34 INFO Client: 
    	 client token: N/A
    	 diagnostics: N/A
    	 ApplicationMaster host: 11.220.203.36
    	 ApplicationMaster RPC port: 30002
    	 queue: queue
    	 start time: 1546691807945
    	 final status: SUCCEEDED
    	 tracking URL: http://jobview.odps.aliyun.com/proxyview/jobview/?h=http://service.cn.maxcompute.aliyun-inc.com/api&p=project_name&i=20190105123647703gpqn26pr2&t=spark&id=application_1546691794888_113905562&metaname=20190105123647703gpqn26pr2&token=TjhlQWswZTRpYWN2L3RuK25VeE5LVy9xSUNjPSxPRFBTX09CTzoxODc1NjUzNjIyNTQzMDYxLDE1NDY5NTEwMzcseyJTdGF0ZW1lbnQiOlt7IkFjdGlvbiI6WyJvZHBzOlJlYWQiXSwiRWZmZWN0IjoiQWxsb3ciLCJSZXNvdXJjZSI6WyJhY3M6b2RwczoqOnByb2plY3RzL3FuX2JlaWppbmcvaW5zdGFuY2VzLzIwMTkwMTA1MTIzNjQ3NzAzZ3BxbjI2cHIyIl19XSwiVmVyc2lvbiI6IjEifQ==
    ```

    1.  通过日志输出的logview在浏览器中可以查看CUPID类型的任务执行的基本信息。

        ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/92656/154703954936677_zh-CN.png)

        单击TaskName为**master-0**任务条，在下方FuxiInstance栏中，通过**All**按钮过滤后，

        ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/92656/154703954936679_zh-CN.png)

        单击TempRoot的StdOut按钮可以查看SparkPi的输出结果：

        ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/92656/154703954936683_zh-CN.png)

    2.  日志中打印出上述的TrackingUrl，表示您的作业已经提交到MaxCompute集群，这个TrackingUrl非常关键，它既是SparkWebUI，也是HistoryServer的Url。在浏览器中打开这个Url，可以追踪Spark作业的运行情况。

        ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/92656/154703954936695_zh-CN.png)

        单击driver的stdout即可以查看Spark作业的输出内容。

        ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/92656/154703954936698_zh-CN.png)


## 约束与限制 {#section_zcq_g5c_kgb .section}

目前MaxCompute Spark支持以下适用场景：

-   Java/Scala 所有离线场景，GraphX、Mllib、RDD、Spark-SQL, PySpark等。
-   读写MaxCompute Table。
-   OSS非结构化存储支持。

暂不支持以下场景\(后续版本陆续支持\)：

-   读写VPC环境下的服务，如RDS、Redis、ECS上部署的服务等。
-   Streaming场景。
-   交互式类需求 Spark-Shell Spark-SQL-Shell PySpark-Shell等。

